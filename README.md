![CLEAR-AI Workshop Banner](workshop.jpg)

# CLEAR-AI Workshop: Collaborative Methods and Tools for Engineering and Evaluating Transparency in AI [ECAI 2025]

## Workshop Schedule

### Morning Session

#### 09:30‚Äì10:30 | Welcome & Introduction
**Presentation:** "Enhancing Active Learning efficiency with a Recommendation System based on Annotator Accuracy, Mood, and Fatigue"  
*Diana Mort√°gua, Luis Macedo and F. Am√≠lcar Cardoso*

---

#### 10:30‚Äì11:00 | ‚òï Coffee Break

---

#### 11:00‚Äì12:30 | Session 1: Presentations

**"A Visual Reader's Eye for Image-Generation AI"**  
*Randi Cecchine and Martha Larson*

**"Uncertainty-Guided Expert-AI Collaboration for Efficient Soil Horizon Annotation"**  
*Teodor Chiaburu, Vipin Singh, Frank Hau√üer and Felix Biessmann*

**"Towards Transparent and Interpretable Credit Risk Models: Classifier Selection Insights from Australia, Germany, and Taiwan"**  
*Krzysztof Lorenz, Piotr Gutowski, Anna Drab-Kurowska, Agnieszka Budziewicz-Gu≈∫lecka, Ewelina Gutowska, Magdalena Majchrzak, Tymoteusz Miller, Irmina Durlik and Ewelina Kostecka*

---

#### 12:30‚Äì14:00 | üçΩÔ∏è Lunch Break

---

### Afternoon Session

#### 14:00‚Äì15:30 | Session 2: Presentations

**"Information Flow Modeling for Transparent and Accountable AI Act Assessment"**  
*Mattias Br√§nnstr√∂m, Themis Xanthopoulou and Lili Jiang*

**"The Machinery of Government: Bureaucracy, Automation and Institutional Black-Boxing"**  
*Diletta Huyskes*

**"Making Privacy Risks Transparent: Causal Analysis of Generalization and Membership Inference Attack in Differentially Private SGD"**  
*Zhou Zhou and Lili Jiang*

---

#### 15:30‚Äì16:00 | ‚òï Coffee Break

---

#### 16:00‚Äì17:00 | Roundtable Discussion
Interactive discussion with presenters and organizers

---

#### 17:00‚Äì17:15 | Closing Remarks

---

## About the Workshop

The CLEAR-AI Workshop brings together researchers, practitioners, and stakeholders to address transparency in AI systems through collaborative and participatory approaches. Below you'll find more details about the workshop's focus, submission guidelines, and how to participate.


## Problem Description
Transparency takes up a central instrumental role in addressing and understanding a wide range of problems from legal to ethical in AI development and deployment. Yet, transparency is often a vague and hard to pin down notion from a objective perspective and is defined differently on different levels in the understanding of AI systems.

In CLEAR we want to approach the problem from the direction of *stakeholder needs* on transparency. By understanding the needs for information we can work to concretely meet these demands. 

The needs on transparency can come from many different sources, such as legal understanding and effective user agency, as such any workable method for this will have to address the participatory aspect of eliciting these needs from the stakeholders.

## Topics of Interest
The workshop welcomes contributions on topics including, but not limited to:
- Innovative methodologies for designing transparent AI systems for meeting stakeholder needs
- Tools, metrics, and techniques for monitoring and ensuring transparency in AI
- Transparency risk assessments
- Participatory design and co-creation methodological approaches involving diverse stakeholders
- Formal frameworks for evaluating transparency
- Case studies and best practices for transparent AI in real-world applications
- Knowledge elicitation methods during participatory settings for AI transparency
- Conceptual translation among stakeholders from diverse backgrounds
- Legal transparency requirements

Submissions should emphasize the integration of technical rigour with societal relevance to address the challenges of building trustworthy AI systems. 

Perspectives on the above issues from under-represented countries are particularly welcome.

## Submission guidelines and Proceedings
Authors are invited to submit full papers of 5,000 to 8,000 words following the ACM guidlines [https://www.acm.org/publications/authors/submissions](https://www.acm.org/publications/authors/submissions) . Submissions will be reviewed by at least two reviewers in a double blind review process. Paper, including transfer papers from the ECAI main track, should be submitted through our Easychair [link](https://easychair.org/conferences?conf=clearwsecai2025). At least one author of each accepted paper is required to register for the workshop and for ECAI. Informal proceedings will be distributed to ECAI 2025 registrants in electronic form.
After the workshop, selected papers can be submitted for publication in a special section of the ACM Journal on Responsible Computing [https://dl.acm.org/journal/jrc](https://dl.acm.org/journal/jrc) .

## Important Dates
- Open for submissions: Tuesday, 15 April 2025
- 1st Paper submission cut-off date: Sunday, 15 June 2025
- Notification date for 1st round of submission: Tuesday, 15 July 2025
- 2nd Paper submission cut-off date (new papers and manual transfer from main conference): Friday,  15 August 2025
- Notification date for 2nd round of submission: Wednesday, 20 August 2025
- Final workshop schedule published: Wednesday, 22 October 2025

## Venue
- EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE (ECAI 2025), Bologna, Italy
- Registration and information: [https://ecai2025.org/](https://ecai2025.org/)


## Background
As AI systems become integral to critical decision-making processes, ensuring their transparency, fairness, and accountability is more essential than ever. Therefore, it is not surprising that the AI Act, the world's first attempt to systematically regulate artificial intelligence, places significant emphasis on this need. In particular, the Act establishes transparency as a fundamental principle, aiming to safeguard user rights and foster trust and reliability in new technologies. In this context, transparency assumes a salient value as a prerequisite for ensuring the fair and responsible development and deployment of AI.

Achieving these objectives necessitates not only the establishment of robust technical frameworks but also the active engagement of a diverse range of stakeholders to ensure that the development of AI is aligned with societal values. In this regard, interdisciplinary research and implementation initiatives have been identified as crucial to facilitate progress in this area.

Following from this, the workshop focuses on advancing the design, monitoring, and evaluation of transparent AI systems. By combining participatory approaches that amplify stakeholder voices with formal methodologies that ensure rigour and reproducibility, the workshop aims to advance the state of the art in trustworthy AI, bridging technical and social perspectives.

The CLEAR-AI Workshop addresses the critical need for interdisciplinary collaboration to advance methods, tools, and evaluation frameworks that ensure transparency, fairness, and trustworthiness in AI systems. In addition, specific focus is put on tackling the challenges emerging from the participatory setting. Submissions should emphasize the integration of technical rigour with societal relevance to address the challenges of building trustworthy AI systems. The CLEAR-AI Workshop aligns with ECAI 2025's mission of advancing sustainable AI by promoting transparency, participatory approaches, and rigorous methods that ensure accountability and societal alignment.


## Format and Structure
The CLEAR-AI Workshop will be a half-day workshop with clustered short paper presentations followed by discussions around the topic. The workshop program will be announced on August 8th.


## Target Audience
The CLEAR-AI Workshop targets an interdisciplinary audience, including:
- Researchers and practitioners in AI, machine learning, and data science
- Experts in human-computer interaction and participatory design
- Ethicists, policymakers, and legal professionals focusing on AI governance
- Developers and engineers working on tools and frameworks for AI transparency
- Stakeholders from academia, industry, and civil society interested in AI transparency

## Organising Committee
- **Themis Dimitra Xanthopoulou**, Department of Computing Science, Ume√• University
- **Rachele Carli**, Department of Computing Science, Ume√• University
- **Andreas Br√§nnstr√∂m**, Department of Computing Science, Ume√• University
- **Francien Dechesne**, eLaw Center for Law and Digital Technologies, Leiden University
- **Chiara Gallese**, Department of Law, University of Turin
- **Mattias Br√§nnstr√∂m**, Founder of Compley AB

## Advisory Board
- Virginia Dignum, AI Policy Lab
- Juan Carlos Nieves, Ume√• University
- Neil Yorke-Smith, TU Delft
- Tim Miller, University of Queensland

## Program Committee
- Tony Ribeiro, Laboratoire des Sciences du Num√©rique de Nantes
- Agate Balayn, TU Delft
- Daniel Kostic, Leiden University
- Giuseppe Primiero, University of Milan
- Jayati Deshmukh, University of Southampton
- Imane Hmiddou, ALLAI
- Amro Najjar, Luxembourg Institute of Science and Technology

## Contact
Please direct any questions regarding the workshop to:
- Themis Dimitra Xanthopoulou, Ume√• University, Sweden, [themis.xanthopoulou@umu.se](mailto:themis.xanthopoulou@umu.se)
