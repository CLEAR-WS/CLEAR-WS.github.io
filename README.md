![CLEAR-AI Workshop Banner](workshop.jpg)

# CLEAR-AI Workshop: Collaborative Methods and Tools for Engineering and Evaluating Transparency in AI [ECAI 2025]

## Problem Description
Transparency takes up a central instrumental role in addressing and understanding a wide range of problems from legal to ethical in AI development and deployment. Yet, transparency is often a vague and hard to pin down notion from a objective perspective and is defined differently on different levels in the understanding of AI systems.

In CLEAR we want to approach the problem from the direction of *stakeholder needs* on transparency. By understanding the needs for information we can work to concretely meet these demands. 

The needs on transparency can come from many different sources, such as legal understanding and effective user agency, as such any workable method for this will have to address the participatory aspect of eliciting these needs from the stakeholders.

## Topics of Interest
The workshop welcomes contributions on topics including, but not limited to:
- Innovative methodologies for designing transparent AI systems for meeting stakeholder needs
- Tools, metrics, and techniques for monitoring and ensuring transparency in AI
- Transparency risk assessments
- Participatory design and co-creation methodological approaches involving diverse stakeholders
- Formal frameworks for evaluating transparency
- Case studies and best practices for transparent AI in real-world applications
- Knowledge elicitation methods during participatory settings for AI transparency
- Conceptual translation among stakeholders from diverse backgrounds
- Legal transparency requirements

Submissions should emphasize the integration of technical rigour with societal relevance to address the challenges of building trustworthy AI systems. 

Perspectives on the above issues from under-represented countries are particularly welcome.

## Submission guidelines and Proceedings
Authors are invited to submit full papers of 5,000 TO 8,000 words following the ACM guidlines [https://www.acm.org/publications/authors/submissions](https://www.acm.org/publications/authors/submissions) . Submissions will be reviewed by at least two reviewers in a double blind review process. Paper should be submitted through our Easychair [link](https://easychair.org/conferences?conf=clearwsecai2025). At least one author of each accepted paper is required to register for the workshop and for ECAI. Informal proceedings will be distributed to ECAI 2025 registrants in electronic form.
After the workshop, selected papers can be submitted for publication in a special section of the ACM Journal on Responsible Computing [https://dl.acm.org/journal/jrc](https://dl.acm.org/journal/jrc) .

## Important Dates
- Open for submissions: Tuesday, 15 April 2025
- Deadline for workshop papers: Thursday, 15 May 2025
- Notification date for workshop papers: Tuesday, 15 July 2025
- Notification of intent to use review transfer option: Tuesday, 1 July 2025
- Final workshop schedule published: Thursday, 8 August 2025

## Venue
- EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE (ECAI 2025), Bologna, Italy
- Registration and information: [https://ecai2025.org/](https://ecai2025.org/)


## Background
As AI systems become integral to critical decision-making processes, ensuring their transparency, fairness, and accountability is more essential than ever. Therefore, it is not surprising that the AI Act, the world's first attempt to systematically regulate artificial intelligence, places significant emphasis on this need. In particular, the Act establishes transparency as a fundamental principle, aiming to safeguard user rights and foster trust and reliability in new technologies. In this context, transparency assumes a salient value as a prerequisite for ensuring the fair and responsible development and deployment of AI.

Achieving these objectives necessitates not only the establishment of robust technical frameworks but also the active engagement of a diverse range of stakeholders to ensure that the development of AI is aligned with societal values. In this regard, interdisciplinary research and implementation initiatives have been identified as crucial to facilitate progress in this area.

Following from this, the workshop focuses on advancing the design, monitoring, and evaluation of transparent AI systems. By combining participatory approaches that amplify stakeholder voices with formal methodologies that ensure rigour and reproducibility, the workshop aims to advance the state of the art in trustworthy AI, bridging technical and social perspectives.

The CLEAR-AI Workshop addresses the critical need for interdisciplinary collaboration to advance methods, tools, and evaluation frameworks that ensure transparency, fairness, and trustworthiness in AI systems. In addition, specific focus is put on tackling the challenges emerging from the participatory setting. Submissions should emphasize the integration of technical rigour with societal relevance to address the challenges of building trustworthy AI systems. The CLEAR-AI Workshop aligns with ECAI 2025's mission of advancing sustainable AI by promoting transparency, participatory approaches, and rigorous methods that ensure accountability and societal alignment.


## Format and Structure
The CLEAR-AI Workshop will be a half-day workshop with clustered short paper presentations followed by discussions around the topic. The workshop program will be announced on August 8th.


## Target Audience
The CLEAR-AI Workshop targets an interdisciplinary audience, including:
- Researchers and practitioners in AI, machine learning, and data science
- Experts in human-computer interaction and participatory design
- Ethicists, policymakers, and legal professionals focusing on AI governance
- Developers and engineers working on tools and frameworks for AI transparency
- Stakeholders from academia, industry, and civil society interested in AI transparency

## Organising Committee
- **Themis Dimitra Xanthopoulou**, Department of Computing Science, Umeå University
- **Rachele Carli**, Department of Computing Science, Umeå University
- **Andreas Brännström**, Department of Computing Science, Umeå University
- **Francien Dechesne**, eLaw Center for Law and Digital Technologies, Leiden University
- **Chiara Gallese**, Department of Law, University of Turin
- **Mattias Brännström**, Founder of Compley AB

## Advisory Board
- Virginia Dignum, AI Policy Lab
- Juan Carlos Nieves, Umeå University
- Neil Yorke-Smith, TU Delft
- Tim Miller, University of Queensland

## Program Committee
- Tony Ribeiro, Laboratoire des Sciences du Numérique de Nantes
- Agate Balayn, TU Delft
- Daniel Kostic, Leiden University
- Giuseppe Primiero, University of Milan
- Jayati Deshmukh, University of Southampton
- Imane Hmiddou, ALLAI
- Amro Najjar, Luxembourg Institute of Science and Technology

## Contact
Please direct any questions regarding the workshop to:
- Themis Dimitra Xanthopoulou, Umeå University, Sweden, [themis.xanthopoulou@umu.se](mailto:themis.xanthopoulou@umu.se)
