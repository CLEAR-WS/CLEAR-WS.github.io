# CLEAR-AI Workshop: Collaborative Methods and Tools for Engineering and Evaluating Transparency in AI

## Venue
- EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE (ECAI 2025)
- Registration and information: [https://ecai2025.org/](https://ecai2025.org/)

## Brief Introduction
As AI systems become integral to critical decision-making processes, ensuring their transparency, fairness, and accountability is more essential than ever. Therefore, it is not surprising that the AI Act, the world's first attempt to systematically regulate artificial intelligence, places significant emphasis on this need. In particular, the Act establishes transparency as a fundamental principle, aiming to safeguard user rights and foster trust and reliability in new technologies. In this context, transparency assumes a salient value as a prerequisite for ensuring the fair and responsible development and deployment of AI.

Achieving these objectives necessitates not only the establishment of robust technical frameworks but also the active engagement of a diverse range of stakeholders to ensure that the development of AI is aligned with societal values. In this regard, interdisciplinary research and implementation initiatives have been identified as crucial to facilitate progress in this area.

Following from this, the workshop focuses on advancing the design, monitoring, and evaluation of transparent AI systems. By combining participatory approaches that amplify stakeholder voices with formal methodologies that ensure rigour and reproducibility, the workshop aims to advance the state of the art in trustworthy AI, bridging technical and social perspectives.

The CLEAR-AI Workshop addresses the critical need for interdisciplinary collaboration to advance methods, tools, and evaluation frameworks that ensure transparency, fairness, and trustworthiness in AI systems. In addition, specific focus is put on tackling the challenges emerging from the participatory setting. Submissions should emphasize the integration of technical rigour with societal relevance to address the challenges of building trustworthy AI systems. The CLEAR-AI Workshop aligns with ECAI 2025's mission of advancing sustainable AI by promoting transparency, participatory approaches, and rigorous methods that ensure accountability and societal alignment.

## Submission
Submissions will undergo a single-blind review process, with each paper evaluated by three Program Committee members. The submission process will be managed using the EasyChair platform.

Accepted papers will be compiled into a pre-proceedings volume, hosted on the AIPEX platform maintained by the AI Policy Lab.

Following the workshop, selected papers may be invited for inclusion in a special issue of a relevant journal (to be determined). Alternatively, we are interested in exploring participation in a potential joint ECAI workshop post-proceedings publication.

## Topics of Interest
The workshop welcomes contributions on topics including, but not limited to:
- Innovative methodologies for designing transparent AI systems
- Tools, metrics, and techniques for monitoring and ensuring accountability in AI
- Participatory design approaches involving diverse stakeholders
- Formal frameworks for evaluating transparency, fairness, and accountability
- Case studies and best practices for transparent AI in real-world applications
- Knowledge elicitation methods during participatory settings for AI transparency
- Knowledge transformation to meet AI transparency needs among stakeholders from diverse backgrounds

Submissions should emphasize the integration of technical rigour with societal relevance to address the challenges of building trustworthy AI systems.

## Format and Structure
The CLEAR-AI Workshop is proposed as a full-day workshop to allow sufficient time for keynote talks, presentations, interactive sessions, and discussions.

The workshop will include the following activities:
- **Keynote**: An invited speaker will present state-of-the-art research and practical insights on participatory and transparent AI systems
- **Paper Presentations**: Selected contributions will be presented in oral and poster sessions
- **Panel Discussion**: A moderated discussion featuring experts from academia, industry, and civil society to address the opportunities and challenges of transparent AI
- **Interactive Sessions**: Breakout groups and participatory design exercises to foster collaboration and hands-on exploration of tools and methods
- **Closing Summary**: A wrap-up session to summarize key insights, identify open challenges, and set a collaborative agenda for future research

## Target Audience
The CLEAR-AI Workshop targets an interdisciplinary audience, including:
- Researchers and practitioners in AI, machine learning, and data science
- Experts in human-computer interaction and participatory design
- Ethicists, policymakers, and legal professionals focusing on AI governance
- Developers and engineers working on tools and frameworks for AI transparency
- Stakeholders from academia, industry, and civil society interested in AI accountability

## Organising Committee
- **Themis Dimitra Xanthopoulou**, Department of Computing Science, Umeå University
- **Rachele Carli**, Department of Computing Science, Umeå University
- **Andreas Brännström**, Department of Computing Science, Umeå University
- **Francien Dechesne**, eLaw Center for Law and Digital Technologies, Leiden University
- **Chiara Gallese**, Department of Law, University of Turin
- **Mattias Brännström**, Founder of Compley AB

## Advisory Board
- Virginia Dignum, AI Policy Lab
- Juan Carlos Nieves, Umeå University
- Neil Yorke-Smith, TU Delft
- Tim Miller, University of Queensland

## Program Committee
- Chiara Gallese, Department of Law, University of Torino, Italy
- Tony Ribeiro, Laboratoire des Sciences du Numérique de Nantes
- Agate Balayn, TU Delft
- Neil Yorke-Smith, TU Delft
- Daniel Kostic, Leiden University
- Giuseppe Primiero, University of Milan
- Jayati Deshmukh, University of Southampton
- Tim Miller, University of Queensland
- Imane Hmiddou, ALLAI
- Amro Najjar

## Contact
Please direct any questions regarding the workshop to:
- Themis Dimitra Xanthopoulou, Umeå University, Sweden, [themis.xanthopoulou@umu.se](mailto:themis.xanthopoulou@umu.se)
